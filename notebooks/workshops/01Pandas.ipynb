{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "appreciated-sample",
   "metadata": {},
   "source": [
    "# Anatomy of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-classics",
   "metadata": {},
   "source": [
    "## Basic Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-argentina",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series are a (comparatively) thin wrapper around arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an array to work with\n",
    "\n",
    "x = np.random.normal(size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a Series\n",
    "\n",
    "simple_series = pd.Series(x)\n",
    "\n",
    "# This contains the same data - but note the index column on the left\n",
    "# All Series objects contain and Index in addition to their data\n",
    "simple_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, this index is an ordinal count (from 0), so the same as numpy/C indexes\n",
    "# But, the similarity ends here!\n",
    "# Pandas indexes are persistent, and will be subsetted along with data\n",
    "\n",
    "simple_series[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas indexes can be of (almost) any datatype\n",
    "# The library includes some very useful and common cases - in particular, the DatetimeIndex\n",
    "# There are many ways to construct these - we will use some of Pandas builtin tools for these examples\n",
    "\n",
    "dti = pd.date_range('1 jun 2000', periods=100, freq='d')\n",
    "\n",
    "# As you can see, this is a special class - it is not a Series or an Array, although it shares some features\n",
    "\n",
    "dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild our Series using the DatetimeIndex\n",
    "\n",
    "date_series = pd.Series(x, index=dti)\n",
    "\n",
    "date_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, indexing into the Series will use the Index data itself as index locations - not simply an integer index\n",
    "\n",
    "start_date = dt.datetime(2000,7,15)\n",
    "\n",
    "date_series[start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatetimeIndexes wrap the standard Python datetime library.  Get to the know this library, it makes working with indexing much easier!\n",
    "\n",
    "end_date = start_date + dt.timedelta(10)\n",
    "\n",
    "start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that unlike indexing with integers, indexing into a Series or DataFrame with a custom index class will\n",
    "# select data inclusively (ie it is a closed interval on both ends) \n",
    "\n",
    "date_series[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can still access the contents of a Series by (0-based) ordinal indexing, by using the iloc method\n",
    "# Note that iloc indexes are also inclusive\n",
    "\n",
    "date_series.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a similar method available that allows indexing by value rather than ordinal indexing\n",
    "# Looks kind of pointless, since we can just use indexes...\n",
    "# It will be important later!\n",
    "\n",
    "date_series.loc[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index of a Series is available as its own object - this will also be very useful later\n",
    "date_series.iloc[0:10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has lots of convenience shortcuts, especially useful for interactive use\n",
    "\n",
    "date_series['jul 2000':'aug 15 2000'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-blink",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "A DataFrame can be thought of as a collection of Series with a shared Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's construct a minimal DataFrame with just one Series - the date_series from above\n",
    "\n",
    "df = pd.DataFrame({'x': date_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far it doesn't contain anything additional to the Series data - with the exception of a Column name, 'x'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are selected using standard indexing\n",
    "# Selecting a single column will return the Series containing that column's data\n",
    "\n",
    "df['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also select columns as if they were member variables of the DataFrame object\n",
    "\n",
    "# Don't!\n",
    "# Don't ever do this!\n",
    "# This looks like it works fine...\n",
    "\n",
    "df.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... but\n",
    "# DataFrames have hundreds of methods and member variables\n",
    "# The moment one of your columns shares a name with them, this happens...\n",
    "\n",
    "bad_df = pd.DataFrame({'columns': [0,1,5,2]})\n",
    "bad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because DataFrames are indexed 'column first', passing index values directly in will cause an error\n",
    "\n",
    "df[start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or maybe they won't?\n",
    "\n",
    "df['jul 2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a big, complicated library with a lot of baggage and technical debt (\"backwards compatibility\")\n",
    "# Wherever possible, use the least ambiguous methods you can\n",
    "# In this case, that is the loc method (I told you it would be important)\n",
    "\n",
    "df.loc[start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's get a more complicated DataFrame from some real AuTuMN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autumn.tools.runs import ManagedRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = ManagedRun(\"covid_19/hume/1633437782/f6ca627\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = mr.calibration.get_mcmc_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters of a calibration run\n",
    "\n",
    "param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see, there are multiple columns in this run; you can access this programatically\n",
    "# Columns is also an Index!  Just one that runs along a different axis\n",
    "\n",
    "param_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple columns can be selected at once.\n",
    "# This is extremely useful in a programattic context, where lists can be generated in code and then used as arguments in indexing\n",
    "\n",
    "param_df[['seasonal_force','vic_2021_seeding.seed_time','contact_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get another DataFrame\n",
    "\n",
    "mcmc_runs_df = mr.calibration.get_mcmc_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean comparisons on Pandas objects produce boolean arrays, just like numpy\n",
    "\n",
    "mcmc_runs_df['run'] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use these to select subsets of Series or DataFrames\n",
    "\n",
    "burned_df = mcmc_runs_df[mcmc_runs_df['run'] > 500]\n",
    "burned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care to make sure your index matches the object you are indexing\n",
    "# The following example will throw an exception in some versions of pandas, but just produce a warning in later versions\n",
    "# Either way - don't do it!  Warnings exist for a reason, and if you see one, there is almost certainly a better way\n",
    "# to write the code that produced it\n",
    "\n",
    "burned_df[mcmc_runs_df['accept'] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same object use for comparison and indexing - no complaints\n",
    "\n",
    "burned_df[burned_df['accept'] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can combine boolean indexes using boolean operators\n",
    "\n",
    "mcmc_runs_df[(mcmc_runs_df['run'] > 500) & (mcmc_runs_df['accept'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still.. that all seems a bit cumbersome\n",
    "# OK, we're going to cheat a little here and use a custom function from the autumn library that makes life with pandas a little easier\n",
    "\n",
    "from autumn.tools.utils.pandas import pdfilt\n",
    "\n",
    "selected_runs = pdfilt(mcmc_runs_df, [\"run > 500\", \"accept == 1\"])\n",
    "selected_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can access the index, and do something useful with it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters from our params_df, using the index of our selected runs\n",
    "\n",
    "param_df.loc[selected_runs.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-syndicate",
   "metadata": {},
   "source": [
    "## Pivots, Melts, MultiIndexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those DataFrames above looked nice.  A little too nice.  Is that even our data?\n",
    "\n",
    "raw_params = mr.calibration.get_mcmc_params(raw=True)\n",
    "\n",
    "raw_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reshape this DataFrame, we use the pivot_table method\n",
    "# This needs to know which columns contain Index data, and which contain Column identifiers\n",
    "# In this case, 'urun' has been handily filled in by combining run and chain in an earlier step, \n",
    "# so we can use this directly as an index\n",
    "\n",
    "raw_params.pivot_table(index='urun',columns='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hang on, that looks a bit weird - we've still got the chain and run columns in there, confusing matters... \n",
    "# Use drop to tidy things up\n",
    "\n",
    "raw_params_urun = raw_params.drop(['chain','run'],axis='columns')\n",
    "raw_params_urun.pivot_table(index='urun',columns='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative, if we don't have a unique identifier, or more importantly want to retain access to both these \n",
    "# \"dimensions\", is to use a MultiIndex\n",
    "# We'll drop 'urun', and build an index using both chain and run\n",
    "\n",
    "midx_df = raw_params.drop('urun',axis='columns').pivot_table(index=['chain','run'], columns='name')\n",
    "midx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndexes work a bit more like multidimensional arrays\n",
    "# You can index by either subsetting on a single dimension...\n",
    "\n",
    "midx_df.loc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or by passing in multidimensional coordinates\n",
    "\n",
    "midx_df.loc[6,13569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because columns are just Indexes on another axis, there can by column MultiIndexes too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbi = mr.powerbi.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = pbi.get_uncertainty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally - if you need to export this data, especially to CSV or a relational database, use melt\n",
    "# This is the inverse of pivot_table\n",
    "\n",
    "# It can require quite a lot of fine tuning, but is important to be aware of\n",
    "\n",
    "udf.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = udf.melt(ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted['date'] = melted.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
